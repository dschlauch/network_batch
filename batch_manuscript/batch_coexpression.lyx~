#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{cite}
\usepackage[T1]{fontenc}
\usepackage{inputenc}
\usepackage{authblk}
\usepackage{lmodern}
\author[1,2]{Daniel Schlauch} 
\author[1]{Joseph Paulson}
\author[2,3]{Kimberly Glass} 
\author[1,3]{John Quackenbush}
\affil[1]{Department of Biostatistics and Computational Biology, Dana-Farber Cancer Institute and Department of Biostatistics, Harvard TH Chan School of Public Health, Boston, MA 02115}
\affil[2]{Channing Division of Network Medicine, Brigham and Women's Hospital, Boston, MA 02115}
\affil[3]{Department of Medicine, Harvard Medical School, Boston, MA 02115}
\affil[4]{Pulmonary and Critical Care Division, Brigham and Women's Hospital and Harvard Medical School, Boston, USA}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Batch effect on covariance structure confounds gene coexpression studies
\end_layout

\begin_layout Abstract
Systemic biases associated with multiple batches of gene expression experiments
 have been known to confound results in differential gene expression analyses.
 Numerous methods have been developed over the past 10 years which address
 this phenomenon.
 Commonly, these approaches adjust expression values such that the mean
 and variance of each gene is conditionally independent of a set of batch
 covariates.
 However, methods published to date have not addressed potential differential
 covariance across batches.
 While this is of lesser concern in the context of standard differential
 gene expression, analyses that utilize a gene coexpression or correlation
 matrix will continue to see confounding due to batch effect even when applied
 to a properly batch-corrected gene expression matrix.
 In this article, we demonstrate the persistence of confounding at the covarianc
e level after standard batch correction using simulation studies and real
 biological examples.
 We present an approach for computing a corrected gene expression coexpression
 matrix, called [NAME], based on a maximum likelihood estimation of the
 conditional covariance matrix.
 [NAME] controls for continuous and categorical confounders, estimates a
 reduced set of parameters, is computationally fast, and makes use of the
 inherently modular structure of features commonly found in genomic analyses.
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
While the accessibility of high-throughput assays increases, so too has
 the ability to investigate numerous hypotheses simultaneously.
 At the heart of most genomic studies is the analysis of the manner in which
 the biological variability of genomic features, such as RNA expression,
 is dependent on phenotypes and other genomic features.
 It can be difficult to ascertain which associations are driven by real
 biological mechanisms and which associations are observed because of confoundin
g by undesirable batch effects.
 It's critical to address this confounding in order to reduce the probability
 of false positive results.
\end_layout

\begin_layout Standard
Biological sources of variation are typically of interest, but observed
 variation is often the result of technical artifacts which may confound
 associations between experimental groups and gene expression.
 We can assume the model 
\begin_inset Formula $G_{ij}=\alpha_{j}+X\beta_{j}+B\gamma_{ij}+\delta_{ij}\epsilon_{ij}$
\end_inset

, where 
\begin_inset Formula $G_{ij}$
\end_inset

 is the gene expression of gene 
\begin_inset Formula $j$
\end_inset

 for sample 
\begin_inset Formula $i$
\end_inset

, 
\begin_inset Formula $X$
\end_inset

 is the design matrix, 
\begin_inset Formula $\beta_{j}$
\end_inset

 is a vector of regression coefficients for gene 
\begin_inset Formula $j$
\end_inset

 for the columns of 
\begin_inset Formula $X$
\end_inset

.
 The next two terms specify the additive and multiplicative impacts of batch.
 
\series bold

\begin_inset Formula $B$
\end_inset


\series default
 is an matrix of indicators for each of the batches, and 
\begin_inset Formula $\gamma_{j}$
\end_inset

 is a vector of additive batch effects on gene 
\begin_inset Formula $j$
\end_inset

.
 
\begin_inset Formula $\epsilon_{ij}$
\end_inset

 is the 
\begin_inset Formula $N\left(0,\sigma_{j}^{2}\right)$
\end_inset

 error term and 
\begin_inset Formula $\delta_{ij}$
\end_inset

 is the multiplier of that error term.
 Controlling for batch necessarily involves estimating the impact of batch
 on the mean expression and the variance of that expression, specifically
 
\begin_inset Formula $\gamma_{ij}$
\end_inset

 and 
\begin_inset Formula $\delta_{ij}$
\end_inset

, for each gene.
 Many steps of experimental protocols have been shown to lead to batch effects,
 but it is generally not known what mechanism is at fault for a particular
 study.
 Therefore, without knowing which features are susceptible to batch effect,
 it is typical to estimate 
\begin_inset Formula $\gamma_{ij}$
\end_inset

 and 
\begin_inset Formula $\delta_{ij}$
\end_inset

 for each gene in a study.
 
\end_layout

\begin_layout Standard
Despite widespread literature published regarding the identification and
 control of confounding due to batch effect 
\begin_inset CommandInset citation
LatexCommand cite
key "chen2011removing,benito2004adjustment,leek2007capturing,johnson2007adjusting"

\end_inset

, batch effect correction has focused on adjusting for the effects of batch
 on gene expression mean and variance at an individual level.
 For example, ComBat 
\begin_inset CommandInset citation
LatexCommand cite
key "johnson2007adjusting"

\end_inset

 uses an empirical bayes approach to estimate the mean and variance parameters
 for each gene and then computes an adjusted gene expression which controls
 for these effects.
 Another approach, Surrogate Variable Analysis, uses a combination of measured
 covariates and singular value decomposition to identify unknown sources
 of variation.
 
\end_layout

\begin_layout Standard
However, in the context of network inference or coexpression analysis, we
 are often interested in the covariance of genes as opposed to the marginal
 distribution of each gene.
 Essentially, we assume that genes which are functionally related will exhibit
 a correlated expression pattern across a set of experimental conditions
 or samples.
 A significant association may indicate a potential functional interaction.
 With this in mind, a natural goal is the identification of those genes
 that are differentially correlated.
 Gene pairs or gene sets that gain or lose a common expression pattern in
 differing experimental conditions may implicate the biological pathways
 or functional mechanisms that drive a particular phenotypic change.
\end_layout

\begin_layout Standard
In estimating coexpression matrices, standard batch correction is critical
 
\begin_inset CommandInset citation
LatexCommand cite
key "furlotte2011mixed"

\end_inset

.
 Confounding due to batch will reduce power, bias results and inevitably
 lead to highly significant, but biologically meaningless associations between
 large volumes of genes.
 Though existing approaches help mitigate this problem current approaches
 fail to remove the impact of the type of batch effect which may manifest
 itself by causing differential coexpression patterns in gene hubs.
 Removing the impact of differential means and variances across batches
 is critical to removing differential covariance across batch, but will
 be insufficient if the covariance itself is associated with batch.
 While numerous methods consider the correlation of genes in adjusting for
 batch, no method that we are aware of allows for that correlation to differ
 according to sample covariates.
 Similarly, no method currently available applies batch correction directly
 to the estimated coexpression matrix.
 
\end_layout

\begin_layout Standard
While the impact of this oversight may be negligible for simple differential
 gene expression analyses, coexpression patterns are widely considered in
 the field of network inference.
 The impact of confounding due to differential coexpression in batches remains
 unexamined.
\end_layout

\begin_layout Standard
Estimation of a coexpression matrix which is adjusted by batches or other
 covariates requires us to allow the gene coexpression to vary by sample.
 This produces at least two major challenges.
 The first problem is that it requires the estimation of additional 
\begin_inset Formula $p\times p$
\end_inset

 matrices in a context that is already suffering from the curse of dimensionalit
y.
 For 
\begin_inset Formula $n\ll p$
\end_inset

, as is the case for high throughput gene expression studies, the fact that
 
\begin_inset Formula ${p \choose 2}$
\end_inset

 parameters must estimated per coexpression matrix is undesirable.
 Recent work has allowed for the imposition of sparsity on the gene covariance
 matrix 
\begin_inset CommandInset citation
LatexCommand cite
key "bien2011sparse"

\end_inset

 or precision matrix 
\begin_inset CommandInset citation
LatexCommand cite
key "friedman2008sparse"

\end_inset

, but the complexity of biological systems make it an imperfect choice for
 sparsity and the computationally burdensome to implement.
 Second, in the case of numerous batches or continuous covariates, it may
 not be possible to estimate a coexpression matrix using the sample covariance
 matrix form, 
\begin_inset Formula $\frac{1}{n}\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)\left(X_{i}-\bar{X}\right)^{T}$
\end_inset

, where 
\begin_inset Formula $X_{i}$
\end_inset

 is the set of all gene expression values for sample 
\begin_inset Formula $i$
\end_inset

.
 
\end_layout

\begin_layout Standard
In the method we describe here, [NAME], we reduce the parameter space by
 estimating 
\begin_inset Formula $p$
\end_inset

 weights for eigenvectors rather than pairwise coexpressions.
 This exploits the modular nature of genomic features, effectively borrowing
 information from similarly behaved genes to estimate gene coexpression
 as a function of sample covariates.
 Our method is presented in a regression framework which allows for the
 inclusion of continuous and categorical covariates into the/ adjustment
 model.
\end_layout

\begin_layout Section
Methods
\end_layout

\begin_layout Subsection
Approach
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename /home/dan/gd/Harvard/Research/network_batch/overview.pdf
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Workflow of 
\series bold
METHOD_NAME
\series default
.
 Draft 1.
 Better space usage, less info.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename /home/dan/gd/Harvard/Research/network_batch/overview2.pdf
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Workflow of 
\series bold
METHODNAME
\series default
.
 Draft 2.
 Possibly more info, less efficient use of space.
\end_layout

\end_inset


\end_layout

\end_inset

The conventional batch correction model is typically given as
\begin_inset Formula 
\[
Y_{g}=\alpha_{g}+\beta_{g}X+\gamma_{i}gZ+\delta_{i}g\epsilon_{i}g
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $X$
\end_inset

 is the exposure (e.g.
 treatment/control) and 
\begin_inset Formula $Z$
\end_inset

 is the batch (or other covariates).
 In the context of network inference, we often want to find 
\begin_inset Formula $cor(Y_{g1},Y_{g2})$
\end_inset

, independent of 
\begin_inset Formula $Z$
\end_inset

.
 
\end_layout

\begin_layout Standard
So, in order to model 2nd order batch, what we really want to do is allow
 for the parameter of interest, 
\begin_inset Formula $\beta_{g}$
\end_inset

 to vary by batch.
 So, now we set
\end_layout

\begin_layout Standard
\begin_inset Formula $\beta_{g}^{*}=\beta_{g}+\beta_{B}gZ$
\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $\beta_{B}$
\end_inset

 is a new parameter that we need to estimate for each of the 
\begin_inset Formula ${p \choose 2}$
\end_inset

 comparisons.
\end_layout

\begin_layout Standard
We can write out a full model for any two genes.
 Note that 
\begin_inset Formula $Y_{g2}$
\end_inset

 is another gene in this model.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Y_{g2}=\alpha_{g}+\beta_{g}^{*}X+\gamma_{i}gZ+\delta_{i}g\epsilon_{i}g
\]

\end_inset


\end_layout

\begin_layout Standard
or
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Y_{g2}=\alpha_{g}+(\beta_{g}+\beta_{B}gZ)X+\gamma_{i}gZ+\delta_{i}g\epsilon_{i}g
\]

\end_inset

 
\begin_inset Formula 
\[
Y_{g2}=\alpha_{g}+\beta_{g}X+\beta_{B}gZX+\gamma_{i}gZ+\delta_{i}g\epsilon_{i}g
\]

\end_inset


\end_layout

\begin_layout Standard
There are many ways to approach this, but I believe the best way is the
 following steps:
\end_layout

\begin_layout Standard
1.
 Apply conventional batch correction.
 This will effectively eliminate the 
\begin_inset Formula $\gamma_{i}gZ$
\end_inset

 term and we can proceed with the simpler model - 
\begin_inset Formula 
\[
Y_{g2}=\alpha_{g}+\beta_{g}X+\beta_{B}ZX+\delta_{i}g\epsilon_{i}g
\]

\end_inset

 - on the combat-corrected data.
 Further standardize each gene expression (this will not impact the actual
 results, but will aid in interpretation and computation time)
\end_layout

\begin_layout Standard
2.
 Fit the following models Reduced: 
\begin_inset Formula 
\[
Y_{g2}=\alpha_{g}+\beta_{g}X+\delta_{i}g\epsilon_{i}g
\]

\end_inset

 Full: 
\begin_inset Formula 
\[
Y_{g2}=\alpha_{g}+\beta_{g}X+\beta_{B}ZX+\delta_{i}g\epsilon_{i}g
\]

\end_inset


\end_layout

\begin_layout Standard
3.
 Place estimated coefficients into two separate matrices (
\begin_inset Formula 
\[
S_{\beta},S_{B}
\]

\end_inset

).
 We have tons of options for computing these coefficients.
 A LASSO-style L1 regularization would probably make the most sense here,
 but for the purposes of simplicity we will start with OLS.
\end_layout

\begin_layout Standard
So, now we have two separate (equal sized) matrices instead of the usual
 one.
 
\begin_inset Formula $S_{\beta}$
\end_inset

 is the estimated similarity matrix and 
\begin_inset Formula $S_{B}$
\end_inset

 is the "batch impact".
 Intuitively, we can imagine that the expected value of 
\begin_inset Formula $S_{B}$
\end_inset

 is a zero matrix in the absence of 2nd order batch effects.
 This lends itself easily for 2nd order batch effect testing - for example,
 we can compare the two models via likelihood ratio test (LRT).
 This is nice, but we're much more interested in 2nd order batch effect
 *correction*.
\end_layout

\begin_layout Standard
4.
 Compute the corrected similarity matrix via: 
\begin_inset Formula 
\[
\hat{S_{i}^{*}}=\hat{S_{\beta}}+(\frac{\sum_{j\in X_{i}}Z_{j}}{n_{i}})\hat{S_{B}}
\]

\end_inset


\end_layout

\begin_layout Standard
This yields a similarity matrix that is **batch-independent**.
 In other words, we can now compare networks computed with different proportions
 of batch membership.
 We can think of the adjusted similarity matrix as being the estimated similarit
y matrix given a *standardized representation of batches*.
 This standardization allows us to compare networks which have been inferred
 with differing batch composition.
\end_layout

\begin_layout Standard
Obviously, the usual caveats apply - this correction is most useful when
 the batches in each exposure are (a) unequal, (b) not too unequal.
 Small numbers of samples for batches will result in wild fluctuations in
 terms of estimating batch effect.
 
\end_layout

\begin_layout Subsection
Model
\end_layout

\begin_layout Standard
Consider a set of 
\begin_inset Formula $N$
\end_inset

 samples with 
\begin_inset Formula $q$
\end_inset

 covariates measuring gene expression across 
\begin_inset Formula $p$
\end_inset

 genes.
 Let 
\begin_inset Formula $\textbf{x}_{i}=(x_{i1},\dots,x_{iq})$
\end_inset

 denote the confounding covariates for sample 
\begin_inset Formula $i$
\end_inset

 and let 
\begin_inset Formula $\textbf{g}_{i}=(g_{i1},\dots,g_{ip})$
\end_inset

 denote the gene expression values for sample 
\begin_inset Formula $i$
\end_inset

 for the 
\begin_inset Formula $p$
\end_inset

 genes.
\end_layout

\begin_layout Standard
In multivariate regression form we can express this as 
\begin_inset Formula 
\[
\textbf{g}_{i}=\mathbf{\beta}^{T}\textbf{x}_{i}+\mathbf{\epsilon}_{i}\text{ for }i=1,\dots,N
\]

\end_inset

 where 
\begin_inset Formula $\mathbf{\beta}$
\end_inset

 is a 
\begin_inset Formula $q\times p$
\end_inset

 matrix of coefficients.
\end_layout

\begin_layout Standard
Equivalently,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\textbf{G}=\textbf{X}\mathbf{\beta}+\mathbf{E}
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\textbf{G}$
\end_inset

, 
\begin_inset Formula $\textbf{X}$
\end_inset

, and 
\begin_inset Formula $\textbf{E}$
\end_inset

 are each matrices with row 
\begin_inset Formula $i$
\end_inset

 corresponding to 
\begin_inset Formula $\textbf{g}_{i}$
\end_inset

, 
\begin_inset Formula $\mathbf{x}_{i}$
\end_inset

, and 
\begin_inset Formula $\mathbf{\epsilon}_{i}$
\end_inset

 respectively.
\end_layout

\begin_layout Standard
Here, we make the usual multivariate assumption for 
\begin_inset Formula $\textbf{E}$
\end_inset

 that the rows 
\begin_inset Formula $\mathbf{\epsilon}_{i},\dots,\mathbf{\epsilon}_{N}$
\end_inset

 are independent, and follow distribution, 
\begin_inset Formula $MVN_{p}(\mathbf{0},\Sigma_{i})$
\end_inset

.
 Notably in this paper, the covariance of 
\begin_inset Formula $\mathbf{\epsilon}_{i}$
\end_inset

 differ according to 
\begin_inset Formula $i$
\end_inset

.
\end_layout

\begin_layout Standard
Estimating the covariance structure for a set of 
\begin_inset Formula $p$
\end_inset

 genes typically involves computing the sample covariance matrix, 
\begin_inset Formula $S$
\end_inset

, with entries 
\begin_inset Formula $s_{jk}=\frac{1}{N-1}\sum_{i=1}^{N}(G_{ij}-\bar{G_{\cdot j}})(G_{ik}-\bar{G_{\cdot k}})$
\end_inset

.
 However, as is typical in high-throughput settings, 
\begin_inset Formula $p\gg N$
\end_inset

, producing an estimated covariance matrix 
\begin_inset Formula $p\times p$
\end_inset

 with column rank 
\begin_inset Formula $\le N$
\end_inset

.
\end_layout

\begin_layout Standard
To address this "curse of dimensionality", numerous methods have been proposed.
 One might use a series of LASSO regressions to estimate parameters in the
 inverse covariance matrix [Meinshausen & Buhlmann (2006)], or perform penalized
 maximum likelihood estimation with the penalty on the inverse covariance
 matrix[Yuan & Lin (2007), Friedman (2007), Banerjee (2008)].
 Each of these approaches imposes sparsity on the precision matrix, effectively
 assuming a large degree of conditional independence between genes.
 More recent work has explored imposing sparsity on the covariance matrix
 itself, rather than the precision matrix [Bien & Tibshirani 2011], which
 allows us to assume widespread marginal independence of genes.
 
\end_layout

\begin_layout Standard
The approach we take here involves estimating a covariance matrix 
\begin_inset Formula $\Sigma_{i}$
\end_inset

 which depends on the batch and experimental design features of sample 
\begin_inset Formula $i$
\end_inset

.
 An estimate of 
\begin_inset Formula $\Sigma_{i}$
\end_inset

 which allows all elements of the matrix to vary freely can be obtained
 by separately estimating the covariance matrix for each unique row of 
\begin_inset Formula $\mathbf{X}$
\end_inset

.
 However, this approach in impractical for a large number of categorical
 covariates or any continuous covariates.
 Given that genes often behave in distinct patterns, it is inefficient to
 estimate coexpression values for every pairwise combination of genes.
\end_layout

\begin_layout Standard
Instead, we approach the problem by making use of the fact that genes commonly
 behave in coexpressed modules, and that the dimensional space is effectively
 much smaller than 
\begin_inset Formula $p^{2}$
\end_inset

.
 To do this, we decompose the gene expression correlation matrix and find
 a set of eigenvectors which explain the variation.
 We then attempt to infer a diagonal matrix of pseudo-eigenvalues, which
 maximize the likelihood function below.
 This procedure allows us to reduce the parameter space from 
\begin_inset Formula $p^{2}$
\end_inset

 to 
\begin_inset Formula $p$
\end_inset

 or less while still considering the bulk of the variability in the data.
\end_layout

\begin_layout Standard
Instead of estimating all entries in the covariance matrix, 
\begin_inset Formula $\Sigma_{i}$
\end_inset

, we instead estimate 
\begin_inset Formula $\Sigma_{i}=\mathbf{Q}\mathbf{\Lambda}^{\left(i\right)}\mathbf{Q}^{T}$
\end_inset

, where 
\begin_inset Formula $\mathbf{Q}$
\end_inset

 is held constant as the set of eigenvectors from the full covariance matrix.
 In this formulation,
\begin_inset Formula $\mathbf{\Lambda}$
\end_inset

 is a diagonal matrix with entries 
\begin_inset Formula 
\begin{equation}
\mathbf{\Lambda}_{kk}^{\left(i\right)}=\mathbf{X}_{i}\mathbf{\gamma}_{\cdot k}\label{eq:Lambda_diag}
\end{equation}

\end_inset

 where 
\begin_inset Formula $\mathbf{X}$
\end_inset

 is the covariate matrix and
\begin_inset Formula $\mathbf{\gamma}$
\end_inset

 is a 
\begin_inset Formula $p\times q$
\end_inset

 matrix of coefficients.
 
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $M_{j}$
\end_inset

 be a 
\begin_inset Formula $p\times p$
\end_inset

 matrix with 
\begin_inset Formula $1$
\end_inset

 at position 
\begin_inset Formula $\left(j,j\right)$
\end_inset

 and 0 at all other positions and let 
\begin_inset Formula $\mathbf{v}_{j}$
\end_inset

 be a 
\begin_inset Formula $p-vector$
\end_inset

 of 0s except for a 1 at position 
\begin_inset Formula $j$
\end_inset

.
 Also, let 
\begin_inset Formula $s$
\end_inset

 be a positive integer with 
\begin_inset Formula $s\le p$
\end_inset

.
 We can express 
\begin_inset Formula $\mathbf{\Lambda}^{\left(i\right)}$
\end_inset

 as
\begin_inset Formula 
\begin{equation}
\mathbf{\Lambda}^{\left(i\right)}=\sum_{j=1}^{s}M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\label{eq:Lambda}
\end{equation}

\end_inset

The value taken with 
\begin_inset Formula $q$
\end_inset

 specifies the number of pseudo-eigenvalues which are to be estimated.
 It is straightforward to show that in the case of a single batch, where
 
\begin_inset Formula $\mathbf{X}=\mathbf{1}_{N}$
\end_inset

, and with 
\begin_inset Formula $q=p$
\end_inset

,
\begin_inset Formula $\mathbf{\gamma}$
\end_inset

 becomes the vector of eigenvalues from the original covariance matrix.
\end_layout

\begin_layout Subsection
Likelihood function
\end_layout

\begin_layout Standard
The likelihood function for a multivariate normal with mean 
\begin_inset Formula $\mathbf{\mu}$
\end_inset

 and variance-covariance 
\begin_inset Formula $\Sigma$
\end_inset

 is 
\begin_inset Formula 
\[
\mathcal{L}\left(\mu,\Sigma\right)=\prod_{i=1}^{N}\frac{1}{\left(2\pi\right)^{\frac{p}{2}}|\Sigma|^{\frac{1}{2}}}e^{-\frac{1}{2}\left(\mathbf{G}_{i}-\mu\right)^{T}\Sigma_{i}^{-1}\left(\mathbf{G}_{i}-\mu\right)}
\]

\end_inset


\end_layout

\begin_layout Standard
The maximum likelihood estimation of 
\begin_inset Formula $\mathbf{\mu}$
\end_inset

 is simply the vector 
\begin_inset Formula $\mathbf{\bar{g}}=\frac{\sum_{i=1}^{N}\mathbf{g}_{i}}{N}$
\end_inset

 and since 
\begin_inset Formula $\mathbf{\mu}$
\end_inset

 is independent of 
\begin_inset Formula $\Sigma$
\end_inset

, we can subtract off the rowmeans yielding 
\begin_inset Formula $\mathbf{G}_{i}^{*}=\mathbf{G}_{i}-\mathbf{\bar{g}}$
\end_inset

.
 And plugging in our index dependent covariance matrix from equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:Lambda"

\end_inset

 we have
\begin_inset Formula 
\[
\mathcal{L}\left(\mathbf{\gamma}\right)=\prod_{i=1}^{N}\frac{1}{\left(2\pi\right)^{\frac{p}{2}}|\mathbf{Q}\sum_{j=1}^{s}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}|^{\frac{1}{2}}}e^{-\frac{1}{2}\left(\mathbf{G}_{i}^{*}\right)^{T}\left(\mathbf{Q}\sum_{j=1}^{s}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\left(\mathbf{G}_{i}^{*}\right)}
\]

\end_inset


\end_layout

\begin_layout Standard
and the log-likelihood is: 
\begin_inset Formula 
\begin{align*}
log\mathcal{L}\left(\mathbf{\gamma}\right)\propto & \frac{-1}{2}\sum_{i=1}^{N}log\left(det\left(\mathbf{Q}\sum_{j=1}^{s}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)\right)\\
 & -\frac{1}{2}\sum_{i=1}^{N}\left[\mathbf{G}_{i}^{*T}\left(\mathbf{Q}\sum_{j=1}^{s}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\mathbf{G}_{i}^{*}\right]\\
= & \frac{-1}{2}\sum_{i=1}^{N}log\left(det\left(\mathbf{Q}diag\left(\mathbf{X}_{i}\gamma\right)\mathbf{Q}^{T}\right)\right)\\
 & -\frac{1}{2}\sum_{i=1}^{N}tr\left[\left(\mathbf{Q}diag\left(\mathbf{X}_{i}\gamma\right)\mathbf{Q}^{T}\right)^{-1}\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right]\text{ The trace trick}\\
\\
\\
\\
\\
 & -\frac{1}{2}\sum_{i=1}^{N}tr\left[\left(\mathbf{Q}diag\left(\mathbf{X}_{i}\left[\gamma+d\gamma\right]\right)\mathbf{Q}^{T}\right)^{-1}\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right]\\
 & -\frac{1}{2}\sum_{i=1}^{N}tr\left[\left(\mathbf{Q}diag\left(\mathbf{X}_{i}\left[\gamma+d\gamma\right]\right)\mathbf{Q}^{T}\right)^{-1}\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right]\\
 & -\frac{1}{2}\sum_{i=1}^{N}tr\left[\left(\mathbf{Q}diag\left(\mathbf{X}_{i}\gamma\right)\mathbf{Q}^{T}+\mathbf{Q}diag\left(\mathbf{X}_{i}d\gamma\right)\mathbf{Q}^{T}\right)^{-1}\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right]\\
 & -\frac{1}{2}\sum_{i=1}^{N}tr\left[\left(\mathbf{Q}diag\left(\mathbf{X}_{i}\gamma\right)\mathbf{Q}^{T}+\mathbf{Q}diag\left(\mathbf{X}_{i}d\gamma\right)\mathbf{Q}^{T}\right)^{-1}\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right]+\frac{1}{2}\sum_{i=1}^{N}tr\left[\left(\mathbf{Q}diag\left(\mathbf{X}_{i}\gamma\right)\mathbf{Q}^{T}\right)^{-1}\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right]\\
 & =-\frac{1}{2}\sum_{i=1}^{N}tr\left[\left(\mathbf{Q}diag\left(\mathbf{X}_{i}\gamma\right)\mathbf{Q}^{T}+\mathbf{Q}diag\left(\mathbf{X}_{i}d\gamma\right)\mathbf{Q}^{T}\right)^{-1}\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}-\left(\mathbf{Q}diag\left(\mathbf{X}_{i}\gamma\right)\mathbf{Q}^{T}\right)^{-1}\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right]\\
 & =-\frac{1}{2}\sum_{i=1}^{N}tr\left[\left[\left(\mathbf{Q}diag\left(\mathbf{X}_{i}\gamma\right)\mathbf{Q}^{T}+\mathbf{Q}diag\left(\mathbf{X}_{i}d\gamma\right)\mathbf{Q}^{T}\right)^{-1}-\left(\mathbf{Q}diag\left(\mathbf{X}_{i}\gamma\right)\mathbf{Q}^{T}\right)^{-1}\right]\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right]\\
 & =-\frac{1}{2}\sum_{i=1}^{N}tr\left[\left[-\left(I_{p}+\left(\mathbf{Q}diag\left(\mathbf{X}_{i}\gamma\right)\mathbf{Q}^{T}\right)^{-1}\mathbf{Q}diag\left(\mathbf{X}_{i}d\gamma\right)\mathbf{Q}^{T}\right)^{-1}\left(\mathbf{Q}diag\left(\mathbf{X}_{i}\gamma\right)\mathbf{Q}^{T}\right)^{-1}\mathbf{Q}diag\left(\mathbf{X}_{i}d\gamma\right)\mathbf{Q}^{T}\left(\mathbf{Q}diag\left(\mathbf{X}_{i}\gamma\right)\mathbf{Q}^{T}\right)^{-1}\right]\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right]\\
 & \text{−}(I+A\text{−}1B)\text{−}1A\text{−}1BA\text{−}1\\
\\
\\
\end{align*}

\end_inset

See 
\series bold
http://math.stackexchange.com/questions/17776/inverse-of-the-sum-of-matrices
\series default

\begin_inset Formula 
\begin{align*}
dln\mathcal{L}\gamma= & \frac{-1}{2}\sum_{i=1}^{N}tr\left[\left(\mathbf{Q}diag\left(\mathbf{X}_{i}\gamma\right)\mathbf{Q}^{T}\right)^{-1}diag\left(\sum_{k=1}^{q}\mathbf{X}_{ik}\right)\right]+\frac{1}{2}\sum_{i=1}^{N}\left[\left(\mathbf{Q}diag\left(\mathbf{X}_{i}\gamma\right)\mathbf{Q}^{T}\right)^{-1}diag\left(\sum_{k=1}^{q}\mathbf{X}_{ik}\right)\left(\mathbf{Q}diag\left(\mathbf{X}_{i}\gamma\right)\mathbf{Q}^{T}\right)^{-1}\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right]\\
0= & \frac{-1}{2}\sum_{i=1}^{N}tr\left[\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}diag\left(\sum_{k=1}^{q}\mathbf{X}_{ik}\right)-\sum_{i=1}^{N}\left[\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}diag\left(\sum_{k=1}^{q}\mathbf{X}_{ik}\right)\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right]\right]\\
0= & \sum_{i=1}^{N}tr\left[\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}diag\left(\sum_{k=1}^{q}\mathbf{X}_{ik}\right)d\gamma\right)^{-1}\left(I_{p}-\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\left(\mathbf{Q}diag\left(\mathbf{X}_{i}\gamma\right)\mathbf{Q}^{T}\right)^{-1}\right)\right]\\
I_{p}= & \sum_{i=1}^{N}\left(\mathbf{Q}diag\left(\mathbf{X}_{i}\gamma\right)\mathbf{Q}^{T}\right)^{-1}\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\\
1=\\
\\
\\
\hat{\gamma}= & \mathbf{\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}}\\
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
log\mathcal{L}\left(\mathbf{\gamma}\right)\propto & \frac{-1}{2}\sum_{i=1}^{N}log\left(det\left(\mathbf{Q}\sum_{j=1}^{s}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)\right)\\
 & -\frac{1}{2}\sum_{i=1}^{N}\left[\mathbf{G}_{i}^{*T}\left(\mathbf{Q}\sum_{j=1}^{s}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\mathbf{G}_{i}^{*}\right]\\
= & \frac{-1}{2}\sum_{i=1}^{N}log\left(det\left(\mathbf{Q}\sum_{j=1}^{s}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)\right)\\
 & -\frac{1}{2}\sum_{i=1}^{N}tr\left[\left(\mathbf{Q}\sum_{j=1}^{s}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right]\text{ The trace trick}\\
= & \frac{-1}{2}\sum_{i=1}^{N}log\left(det\left(\mathbf{Q}\right)det\left(\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\right)det\left(\mathbf{Q}^{T}\right)\right)-\frac{1}{2}\sum_{i=1}^{N}tr\left[\mathbf{G}_{i}^{*T}\mathbf{G}_{i}^{*}\left(\mathbf{Q}\sum_{j=1}^{s}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\right]\text{ property of determinant}\\
= & \frac{-1}{2}\sum_{i=1}^{N}log\left(det\left(\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\right)\right)-\frac{1}{2}\sum_{i=1}^{N}tr\left[\mathbf{G}_{i}^{*T}\mathbf{G}_{i}^{*}\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\right]\text{ det of eigenvectors is 1}\\
\frac{\partial}{\partial\gamma}log\mathcal{L}\left(\mathbf{\gamma}\right)= & \frac{-1}{2}\sum_{i=1}^{N}tr\left[\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\sum_{j=1}^{p}\left[M_{j}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]^{T}\right]+\frac{1}{2}\sum_{i=1}^{N}tr\left[\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\left(\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right)\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\right]\\
= & \frac{-1}{2}\sum_{i=1}^{N}tr\left[\sum_{j=1}^{p}\left[M_{j}\mathbf{X}_{i}^{T}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\right]+\frac{1}{2}\sum_{i=1}^{N}\left[\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\left(\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right)\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\right]\\
= & \frac{-1}{2}\sum_{i=1}^{N}\left[\sum_{j=1}^{p}\left[\mathbf{X}_{i}^{T}\mathbf{\gamma}\mathbf{X}_{i}\right]\right]+\frac{1}{2}\sum_{i=1}^{N}\left[\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\left(\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right)\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\right]\\
= & \frac{-1}{2}\sum_{i=1}^{N}\left[\sum_{j=1}^{p}\left[\mathbf{X}_{i}^{T}\mathbf{\gamma}\mathbf{X}_{i}\right]\right]+\frac{1}{2}\sum_{i=1}^{N}\left[\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\left(\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right)\left(\mathbf{Q}^{-T}\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\right)^{-1}\right)\right]\\
= & \frac{-1}{2}\sum_{i=1}^{N}\left[\sum_{j=1}^{p}\left[\mathbf{X}_{i}^{T}\mathbf{\gamma}\mathbf{X}_{i}\right]\right]+\frac{1}{2}\sum_{i=1}^{N}\left[\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\left(\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right)\left(\mathbf{Q}^{-T}\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]^{-1}\mathbf{Q}^{-1}\right)\right]\\
\sum_{i=1}^{N}\left[\sum_{j=1}^{p}\left[\mathbf{X}_{i}^{T}\mathbf{\gamma}\mathbf{X}_{i}\right]\right]= & \sum_{i=1}^{N}\left[\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\left(\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right)\left(\mathbf{Q}^{-T}\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]^{-1}\mathbf{Q}^{-1}\right)\right]\\
\\
0= & \sum_{i=1}^{N}\left[tr\left[\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\sum_{j=1}^{p}\left[M_{j}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]^{T}\right]+\left[\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\left(\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right)\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\right]\right]\text{\,each term is pos-def}\\
0= & \sum_{i=1}^{N}\left[tr\left[\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\sum_{j=1}^{p}\left[M_{j}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]^{T}\right]+\left[\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\left(\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right)\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\right]\right]\\
\\
\sum_{i=1}^{N}tr\left[\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\sum_{j=1}^{p}\left[M_{j}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]^{T}\right]= & \sum_{i=1}^{N}\left[\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\left(\sum_{i=1}^{N}\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right)\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{\gamma}\mathbf{X}_{i}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
log\mathcal{L}\left(\mathbf{\gamma}\right)= & \frac{-1}{2}\sum_{i=1}^{N}log\left(\prod_{j=1}^{p}\left[\mathbf{X}_{i}\mathbf{\gamma}_{\cdot j}\right]\right)-\frac{1}{2}\sum_{i=1}^{N}tr\left[\mathbf{G}_{i}^{*T}\mathbf{G}_{i}^{*}\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{X}_{i}\mathbf{\gamma}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\right]\text{ det of diagonal matrix is product of diag}\\
= & \frac{-1}{2}\sum_{i=1}^{N}\sum_{j=1}^{p}log\left(\mathbf{X}_{i}\mathbf{\gamma}_{\cdot j}\right)-\frac{1}{2}\sum_{i=1}^{N}tr\left[\mathbf{G}_{i}^{*T}\mathbf{G}_{i}^{*}\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{X}_{i}\mathbf{\gamma}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\right]\text{ algebra}\\
= & \frac{-1}{2}\sum_{i=1}^{N}\left[\sum_{j=1}^{p}log\left(\mathbf{X}_{i}\mathbf{\gamma}_{\cdot j}\right)-tr\left[\mathbf{G}_{i}^{*T}\mathbf{G}_{i}^{*}\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{X}_{i}\mathbf{\gamma}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\right]\right]\text{ algebra}\\
\frac{\partial}{\partial\gamma}log\mathcal{L}\left(\mathbf{\gamma}\right)= & \frac{-1}{2}\sum_{i=1}^{N}\left[\frac{\partial}{\partial\gamma}\sum_{j=1}^{p}log\left(\mathbf{X}_{i}\mathbf{\gamma}_{\cdot j}\right)+\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{X}_{i}\mathbf{\gamma}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\left(\sum_{i=1}^{N}\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right)\left(\mathbf{Q}\sum_{j=1}^{p}\left[M_{j}\mathbf{X}_{i}\mathbf{\gamma}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\right]\\
\\
\\
\\
\\
\\
d\,log\mathcal{L}\left(\mathbf{\gamma}\right) & =\frac{-1}{2}\sum_{i=1}^{N}tr\left[\left(\mathbf{Q}\sum_{j=1}^{s}\left[M_{j}\mathbf{X}_{i}\mathbf{\gamma}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\right]-\frac{1}{2}\left[-\left(\mathbf{Q}\sum_{j=1}^{s}\left[M_{j}\mathbf{X}_{i}\mathbf{\gamma}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\left(\sum_{i=1}^{N}\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right)\left(\mathbf{Q}\sum_{j=1}^{s}\left[M_{j}\mathbf{X}_{i}\mathbf{\gamma}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\right]\\
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Setting 
\begin_inset Formula $\mathbf{U}_{i}=\mathbf{Q}\sum_{j=1}^{s}\left[M_{j}\mathbf{X}_{i}\mathbf{\gamma}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}$
\end_inset

 and applying the chain run for differentiating with respect to 
\begin_inset Formula $\gamma$
\end_inset

 yields
\begin_inset Formula 
\begin{align*}
log\mathcal{L}\left(\mathbf{U}\right) & =\frac{-1}{2}\sum_{i=1}^{N}log\left(det\left(\mathbf{U}_{i}\right)\right)-\frac{1}{2}\sum_{i=1}^{N}tr\left[\mathbf{G}_{i}^{*}\mathbf{U}_{i}^{-1}\mathbf{G}_{i}^{*T}\right]\\
 & =\frac{-1}{2}\sum_{i=1}^{N}log\left(det\left(\mathbf{U}_{i}\right)\right)-\frac{1}{2}\sum_{i=1}^{N}tr\left[\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\mathbf{U}_{i}^{-1}\right]\\
 & =\frac{-1}{2}\sum_{i=1}^{N}log\left(det\left(\mathbf{U}_{i}\right)\right)-\frac{1}{2}tr\left(\sum_{i=1}^{N}\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\mathbf{U}_{i}^{-1}\right)\\
\frac{\partial log\mathcal{L}\left(\mathbf{U}\right)}{\partial\mathbf{U}} & =\frac{-1}{2}\sum_{i=1}^{N}tr\left[\mathbf{U}^{-1}\right]\frac{\partial\mathbf{U}}{\partial\gamma}-\frac{1}{2}\left[-\mathbf{U}^{-1}\left(\sum_{i=1}^{N}\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}\right)\mathbf{U}^{-1}\right]\frac{\partial\mathbf{U}}{\partial\gamma}\\
\mathbf{U} & =\sum_{j=1}^{s}\left[\mathbf{Q}M_{j}\mathbf{X}_{i}\mathbf{\gamma}\mathbf{v}_{j}^{T}\mathbf{Q}^{T}\right]\\
\frac{\partial\mathbf{U}}{\partial\gamma} & =\sum_{j=1}^{s}\left[\mathbf{X}_{i}^{T}M_{j}^{T}\mathbf{Q}^{T}\mathbf{Q}\mathbf{v}_{j}\right]\\
\frac{\partial\mathbf{U}}{\partial\gamma} & =\sum_{j=1}^{s}\left[\mathbf{X}_{i}^{T}M_{j}^{T}\mathbf{v}_{j}\right]\\
\frac{\partial log\mathcal{L}\left(\mathbf{\gamma}\right)}{\partial\gamma} & =\frac{-1}{2}\sum_{i=1}^{N}tr\left[\left(\sum_{j=1}^{s}\left[\mathbf{Q}M_{j}\mathbf{X}_{i}\mathbf{\gamma}\mathbf{v}_{j}^{T}\mathbf{Q}^{T}\right]\right)^{-1}\right]\sum_{j=1}^{s}\left[\mathbf{X}_{i}^{T}M_{j}^{T}\mathbf{v}_{j}\right]-\\
 & \frac{1}{2}\left[-\left(\sum_{j=1}^{s}\left[\mathbf{Q}M_{j}\mathbf{X}_{i}\mathbf{\gamma}\mathbf{v}_{j}^{T}\mathbf{Q}^{T}\right]\right)^{-T}\left(\sum_{i=1}^{N}\mathbf{G}_{i}^{*T}\mathbf{G}_{i}^{*}\right)^{T}\left(\sum_{j=1}^{s}\left[\mathbf{Q}M_{j}\mathbf{X}_{i}\mathbf{\gamma}\mathbf{v}_{j}^{T}\mathbf{Q}^{T}\right]\right)^{-T}\right]\sum_{j=1}^{s}\left[\mathbf{X}_{i}^{T}M_{j}^{T}\mathbf{v}_{j}\right]\\
\end{align*}

\end_inset

Setting equal to 0 and removing terms we get
\begin_inset Formula 
\begin{align*}
\left(\sum_{j=1}^{s}\left[\mathbf{Q}M_{j}\mathbf{X}_{i}\mathbf{\gamma}\mathbf{v}_{j}^{T}\mathbf{Q}^{T}\right]\right)^{-T}\left(\sum_{i=1}^{N}\mathbf{G}_{i}^{*T}\mathbf{G}_{i}^{*}\right)^{T}\left(\sum_{j=1}^{s}\left[\mathbf{Q}M_{j}\mathbf{X}_{i}\mathbf{\gamma}\mathbf{v}_{j}^{T}\mathbf{Q}^{T}\right]\right)^{-T} & =\sum_{i=1}^{N}tr\left[\left(\sum_{j=1}^{s}\left[\mathbf{Q}M_{j}\mathbf{X}_{i}\mathbf{\gamma}\mathbf{v}_{j}^{T}\mathbf{Q}^{T}\right]\right)^{-1}\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
==========
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
d\,log\mathcal{L}\left(\mathbf{\gamma}\right) & =\frac{-1}{2}\sum_{i=1}^{N}tr\left(\mathbf{Q}\sum_{j=1}^{s}\left[M_{j}\mathbf{X}_{i}\mathbf{\gamma}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}d\gamma\\
 & -\frac{1}{2}tr\left[-\sum_{i=1}^{N}\left(\mathbf{Q}\sum_{j=1}^{s}\left[M_{j}\mathbf{X}_{i}\mathbf{\gamma}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}d\gamma\left(\mathbf{Q}\sum_{j=1}^{s}\left[M_{j}\mathbf{X}_{i}\mathbf{\gamma}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\mathbf{G}_{i}^{*T}\mathbf{G}_{i}^{*}\right]\\
\end{align*}

\end_inset

 To find the maximum, we set 
\begin_inset Formula $d\,log\mathcal{L}\left(\mathbf{\gamma}\right)=0$
\end_inset

.
 This is satisfied when
\begin_inset Formula 
\begin{align*}
0 & =-\frac{1}{2}tr\left(\sum_{i=1}^{N}\left(\mathbf{Q}\sum_{j=1}^{s}\left[M_{j}\mathbf{X}_{i}\mathbf{\gamma}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}d\gamma\left(I_{p}-\sum_{i=1}^{N}\left(\mathbf{Q}\sum_{j=1}^{s}\left[M_{j}\mathbf{X}_{i}\mathbf{\gamma}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)^{-1}\sum_{i=1}^{N}\mathbf{G}_{i}^{*T}\mathbf{G}_{i}^{*}\right)\right)\\
\end{align*}

\end_inset

This is satisfied when the right term is 0, or when 
\begin_inset Formula 
\[
\sum_{i=1}^{N}\left(\mathbf{Q}\sum_{j=1}^{s}\left[M_{j}\mathbf{X}_{i}\mathbf{\gamma}\mathbf{v}_{j}^{T}\right]\mathbf{Q}^{T}\right)=\sum_{i=1}^{N}\mathbf{G}_{i}^{*}\mathbf{G}_{i}^{*T}
\]

\end_inset

Answer:
\begin_inset Formula 
\[
\hat{\gamma}=\mathbf{Q}^{-1}\tilde{\mathbf{G}}diag\left(\left(\mathbf{X}^{T}\mathbf{X}\right)^{-1}\mathbf{X}^{T}\right)\tilde{\mathbf{G}}^{T}\mathbf{Q}^{-T}
\]

\end_inset


\begin_inset Formula 
\[
\hat{\gamma}_{i}=\mathbf{Q}^{-1}\tilde{\mathbf{G}}diag\left(\left[\left(\mathbf{X}^{T}\mathbf{X}\right)^{-1}\mathbf{X}^{T}\right]_{i}\right)\tilde{\mathbf{G}}^{T}\mathbf{Q}^{-T}
\]

\end_inset


\end_layout

\begin_layout Subsection
Properties of this estimator
\end_layout

\begin_layout Standard
We refer to this estimate as the re-estimate because we are recomputing
 the eigenvalues after previously computing the covariate-naive eigendecompositi
on.
 The re-estimate has a number of advantageous statistical and computational
 properties.
\end_layout

\begin_layout Enumerate
This solution is closed form.
 
\end_layout

\begin_deeper
\begin_layout Enumerate
Can be implemented with linear algebra.
\end_layout

\begin_layout Enumerate
Has an exact answer.
\end_layout

\begin_layout Enumerate
Is computationally fast...
 (2000 genes, 400 samples runs in 11.6s!) (See supporting Methods and Materials)
\end_layout

\end_deeper
\begin_layout Enumerate
This solution is the maximum likelihood estimate
\end_layout

\begin_deeper
\begin_layout Enumerate
Sufficiency: The mle depends on the sample observations only through the
 value of a sufficient statistic.
\end_layout

\begin_layout Enumerate
Invariance: The maximum likelihood estimate is invariant under functional
 transformations.
 That is, if 
\begin_inset Formula $T=t(X_{1},\ldots,X_{n})$
\end_inset

 is the mle of 
\begin_inset Formula $\theta$
\end_inset

 and if 
\begin_inset Formula $u(\theta)$
\end_inset

 is a function of 
\begin_inset Formula $\theta$
\end_inset

, then 
\begin_inset Formula $u(T)$
\end_inset

 is the mle of 
\begin_inset Formula $u(\theta)$
\end_inset

.
 
\end_layout

\begin_layout Enumerate
Consistency: The maximum likelihood estimator is consistent.
\end_layout

\begin_layout Enumerate
Efficiency: If there is a MVB estimator of 
\begin_inset Formula $\theta$
\end_inset

, the method of maximum likelihood will produce it.
\end_layout

\begin_layout Enumerate
Asymptotic Normality
\end_layout

\end_deeper
\begin_layout Subsection
Corrected covariance matrix
\end_layout

\begin_layout Standard
With the estimates obtained with our method, it is straightforward to see
 how fitted values for the covariance matrix for each sample or experimental
 condition can be obtained.
 Given an estimate for 
\begin_inset Formula $\gamma$
\end_inset

, 
\begin_inset Formula $\hat{\gamma}$
\end_inset

, we can now estimate the batch-independent covariance structure as 
\begin_inset Formula 
\[
\hat{\mathbf{S}}=\mathbf{Q}diag\left(\bar{\mathbf{X}}\hat{\gamma}\right)\mathbf{Q}^{T}
\]

\end_inset

 where 
\begin_inset Formula $\bar{\mathbf{X}}$
\end_inset

 is a 
\begin_inset Formula $q$
\end_inset

-vector specifying the column means of 
\begin_inset Formula $\bar{\mathbf{X}}$
\end_inset

,
\begin_inset Formula 
\[
\bar{\mathbf{X}}=\frac{\sum_{i=1}^{N}\mathbf{x}_{i}}{N}
\]

\end_inset


\end_layout

\begin_layout Standard
Computing the differential covariance matrix between two conditions, defined
 as column 2 of 
\begin_inset Formula $\mathbf{X}$
\end_inset

, can be performed via 
\begin_inset Formula 
\[
\hat{\mathbf{W}}=\mathbf{Q}diag\left(\mathbf{y}\hat{\gamma}\right)\mathbf{Q}^{T}
\]

\end_inset

where 
\begin_inset Formula $\mathbf{y}=\left(0,1,0,\dots0\right)_{q}$
\end_inset


\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Subsection
Simulated Demonstration
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename temp_eclipse_figure_20717.png
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Separation of rewired ECLIPSE data
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Consider a set of samples from a study involving two batches.
 Let the expression data be distributed as a set of MVN with mean vector
 
\begin_inset Formula $\mu$
\end_inset

 and covariance structure 
\begin_inset Formula $\Sigma$
\end_inset

.
\end_layout

\begin_layout Standard
Existing batch correction methods are designed to identify differentially
 expressed genes and thus focus on 
\begin_inset Formula $\mu$
\end_inset

 and the diagonal of 
\begin_inset Formula $\Sigma$
\end_inset

.
\end_layout

\begin_layout Standard
For network inference, however, we are less interested in these values and
 more interesting in the off-diagonal of 
\begin_inset Formula $\Sigma$
\end_inset

.
 Mechanisms for batch effect which act on the covariance structure rather
 than the mean and variance structure will not be corrected for using existing
 batch correction methods.
\end_layout

\begin_layout Standard
In Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "simulated_example"

\end_inset

, we see two examples of uncorrected batch effect (Left) impacting two genes
 in a study.
 In the top row, batch effect alters the means and variances of the two
 genes.
 In the bottom row, the means, variances 
\emph on
and
\emph default
 coexpression is impacted.
 Upon application of ComBat (Right) to the uncorrelated genes, the two genes
 become independent as desired.
 However, when applied to the conditionally coexpressed case (Bottom row)
 we continue to observe differential coexpression across batches.
\end_layout

\begin_layout Standard
To demonstrate the general concept of how differential coexpression leads
 to inflated test statistics, we simulated two studies, each of 200 individuals
 across 10,000 genes.
 Each sample was a realization of a multivariate normal distribution with
 
\begin_inset Formula $\mathbf{\mu}=\mathbf{0}_{p},$
\end_inset

 and borrowed a coexpression matrix of 10,000 genes from an existing dataset
 (ECLIPSE) to be 
\begin_inset Formula $\mathbf{\Sigma}$
\end_inset

.
 For Study 1, we sampled 200 times from this distribution.
 For Study 2, we sampled 150 times using 
\begin_inset Formula $\Sigma$
\end_inset

, and then estimated a new 
\begin_inset Formula $\Sigma^{*}$
\end_inset

 using 9000 of the same genes from the ECLIPSE study, but with 1000 new
 genes.
 This procedure was intended to mimic the introduction of newly active biologica
l pathways in a subset of the samples as we might expect with batch effect.
 Our goal was to observe how the distribution of the estimated coexpression
 matrix differed according to the different covariance approaches.
 The results are seen in Figure 2, showing an inflation of significant results...
 
\series bold
[describe this in more detail]
\end_layout

\begin_layout Standard
Second order batch effect in GTEx clearly exists (see above), but it can
 be subtle.
 For the purposes of a proof on concept, we can generate a much stronger
 batch effect which clearly demonstrates this approach.
 We simply select 5000 genes and 5000 separate genes in the other batch,
 relabeling them Gene1, Gene2,…, Gene5000.
 Basically, we’re simply mismatching the genes between the batches! This,
 obviously, causes a completely random rewiring of the network from one
 batch to the other.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/simulated_example.png
	lyxscale 25
	width 100col%

\end_inset


\begin_inset Graphics
	filename figures/pasted2.png
	lyxscale 25
	width 40col%

\end_inset


\begin_inset Graphics
	filename figures/pasted1.png
	lyxscale 25
	width 40col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
In this toy example, we demonstrate which artifacts standard batch correction
 is capable of correcting and which artifacts will remain.
 In A-D, we show plots of two example genes before (left) and after (right)
 correction, colored by their batch.
 In the top row (A,B), we show a comparison of two genes which are conditionally
 independent, and illustrate that batch correction appropriately removes
 the marginal dependence between the genes.
 In the bottom row (C,D), we show two genes that are conditionally coexpressed
 and demonstrate that batch correction may help mitigate the measured coexpressi
on, but the resulting coexpression is a function of the batch membership.
 Importantly when comparing coexpression matrices, differing batch proportions
 will bias the differential coexpression.
 In simulations (See Supp) we demonstrate that in the absence of batched
 differential coexpression, ComBat sufficiently controls the type I error.
 However, when coexpression differs by batch, our false positive rate increases
 above the expectation of the null model.
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "simulated_example"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Batch effect in GTEx Project
\end_layout

\begin_layout Standard
GTEx uses WGCNA to find common modules across tissues.
 [Describe GTEx]
\end_layout

\begin_layout Standard
GTEx Consortium uses state-of-the-art methods for attempting to adjust for
 batch including study design and expression value correction.
\end_layout

\begin_layout Standard
Study design:
\end_layout

\begin_layout Standard

\emph on
\begin_inset Quotes eld
\end_inset

To the extent possible, based on sample availability, batches for library
 construction were designed to include a range of samples from different
 tissues and to span multiple donors, so as to minimise donor and tissue
 batch effects.
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Standard
Expression correction:
\end_layout

\begin_layout Standard

\emph on
\begin_inset Quotes eld
\end_inset

the effect of top 3 PEER factors, gender, and 3 genotype PCs were removed.
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Standard
However, neither of these address the "second order" batch issue.
 These corrections inherently assume that batch affects the location-scale
 distribution of gene expression independently and thus does not consider
 the scenario where coexpression is the feature impacted by batch.
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename figures/gtex_image.png

\end_inset

[GTEx Supplement] [Reproduce this figure or remove it]
\end_layout

\begin_layout Standard
To demonstrate that this study is sensitive to batch, we choose two widely
 available tissue types (Blood and Lung) from the data [YARN normalization].
\end_layout

\begin_layout Standard
We then apply batch correction using 
\begin_inset Quotes eld
\end_inset

Center
\begin_inset Quotes erd
\end_inset

 as the batch of interest.
 We then ran WGCNA on each tissue separately as described in [GTEx paper]
 and compute modules based on Topological Overlap Map.
 
\end_layout

\begin_layout Standard
We then ran the same procedure, but subsetted the data by each of the 3
 centers.
 In theory, after correcting for batch, the modules observed should have
 been independent of the batch used to find them.
 However, we observe dramatic (notable? clear?) differences in the modules
 identified.
 We should really quantify this difference somehow.
 This may require a clever resampling scheme where we select samples both
 randomly and by center to measure variability.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/pasted4.png
	width 40col%

\end_inset


\begin_inset Graphics
	filename figures/pasted5.png
	width 40col%

\end_inset


\end_layout

\begin_layout Plain Layout
A
\begin_inset Graphics
	filename figures/pasted6.png
	width 30col%

\end_inset

B
\begin_inset Graphics
	filename figures/pasted7.png
	width 30col%

\end_inset

C
\begin_inset Graphics
	filename figures/pasted8.png
	width 30col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Make these nicer.
 Combine into single plot? 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Confounding due to sex in ECLIPSE study
\end_layout

\begin_layout Standard
In this analysis, we will perform a very common analysis: Build coexpression
 networks based on 
\emph on
COPD
\emph default
 vs 
\emph on
Smoker control
\emph default
 and identify consensus modules with WGCNA.
 
\emph on
Gender
\emph default
 is treated as a confounder, but is only corrected using standard batch
 correction methods.
\end_layout

\begin_layout Standard
1.
 Run ComBat on gene expression data, *including gender as a covariate*.
 
\end_layout

\begin_layout Standard
2.
 Sample a set of designs from this study which include varying degrees of
 gender imbalance.
 
\end_layout

\begin_layout Standard
3.
 Evaluate the agreement between cases and controls with pseudo-R^2 from
 multinomial logistic regression.
 
\end_layout

\begin_layout Standard
4.
 Determine the degree to which the agreement between cases and controls
 depends on the gender distribution.
\end_layout

\begin_layout Standard
While this data is reasonably balanced, we can use it to demonstrate how
 sensitive our results are to confounding that was 
\emph on
supposedly 
\emph default
accounted for already.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "AgreementVsConfounder"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/pasted9.png
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Very clear dependence of agreement between cases and control on the balance.
 In other words, with a strong lack of balance, we see weaker agreement,
 indicating that the results we DO see are a function of the confounder
 and not the case-control partition.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "AgreementVsConfounder"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section*
Discussion
\end_layout

\begin_layout Standard
Thoughts about impact on any analysis involving coexpression with batches...
\end_layout

\begin_layout Standard
Thoughts about generality of estimating covariance matrices in the context
 of confounding.
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "coexpression_batch"
options "bibtotoc,abbrvnat"

\end_inset


\end_layout

\end_body
\end_document
